2025-03-21 18:13:53,314 INFO    StreamThr :692 [internal.py:wandb_internal():86] W&B internal server running at pid: 692, started at: 2025-03-21 18:13:53.313681
2025-03-21 18:13:53,315 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: status
2025-03-21 18:13:53,320 INFO    WriterThread:692 [datastore.py:open_for_write():87] open: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_181353-seed-llama-8b-GRPO-resq/run-seed-llama-8b-GRPO-resq.wandb
2025-03-21 18:13:53,321 DEBUG   SenderThread:692 [sender.py:send():382] send: header
2025-03-21 18:13:53,337 DEBUG   SenderThread:692 [sender.py:send():382] send: run
2025-03-21 18:13:53,341 INFO    SenderThread:692 [sender.py:_maybe_setup_resume():763] checking resume status for jakhongir-saydaliev-epfl/multimodal_cot/seed-llama-8b-GRPO-resq
2025-03-21 18:13:53,705 INFO    SenderThread:692 [sender.py:_maybe_setup_resume():841] configured resuming with: ResumeState(resumed=True,step=0,history=0,events=3,output=124,runtime=131.612626,wandb_runtime=69,summary={'_wandb': {'runtime': 69}},config={'beta': {'desc': None, 'value': 0.04}, 'bf16': {'desc': None, 'value': True}, 'fp16': {'desc': None, 'value': False}, 'fsdp': {'desc': None, 'value': []}, 'seed': {'desc': None, 'value': 42}, 'tf32': {'desc': None, 'value': None}, 'debug': {'desc': None, 'value': []}, 'optim': {'desc': None, 'value': 'adamw_torch'}, 'top_k': {'desc': None, 'value': 50}, 'top_p': {'desc': None, 'value': 1}, '_wandb': {'desc': None, 'value': {'m': [{'1': 'train/global_step', '6': [3]}], 't': {'1': [1, 11, 41, 49, 51, 55, 63, 71, 83, 84, 98], '2': [1, 11, 41, 49, 51, 55, 63, 71, 83, 84, 98], '3': [5, 7, 13, 19, 23], '4': '3.10.12', '5': '0.16.2', '6': '4.49.0', '8': [5], '9': {'1': 'transformers_trainer'}, '13': 'linux-x86_64'}, 'framework': 'huggingface', 'start_time': 1742580359.620956, 'cli_version': '0.16.2', 'is_jupyter_run': False, 'python_version': '3.10.12', 'is_kaggle_kernel': False, 'huggingface_version': '4.49.0'}}, 'prefix': {'desc': None, 'value': None}, 'do_eval': {'desc': None, 'value': False}, 'no_cuda': {'desc': None, 'value': False}, 'use_cpu': {'desc': None, 'value': False}, 'do_train': {'desc': None, 'value': False}, 'head_dim': {'desc': None, 'value': 128}, 'id2label': {'desc': None, 'value': {'0': 'LABEL_0', '1': 'LABEL_1'}}, 'label2id': {'desc': None, 'value': {'LABEL_0': 0, 'LABEL_1': 1}}, 'mlp_bias': {'desc': None, 'value': False}, 'run_name': {'desc': None, 'value': 'seed-llama-8b-GRPO-resq'}, 'use_ipex': {'desc': None, 'value': False}, 'use_vllm': {'desc': None, 'value': False}, 'adafactor': {'desc': None, 'value': False}, 'data_seed': {'desc': None, 'value': None}, 'deepspeed': {'desc': None, 'value': '/lid/home/saydalie/multimodal_cot/SEED/MultiModalLLM/configs/deepspeed/stage2_bf16.json'}, 'do_sample': {'desc': None, 'value': False}, 'hub_token': {'desc': None, 'value': '<HUB_TOKEN>'}, 'log_level': {'desc': None, 'value': 'info'}, 'max_steps': {'desc': None, 'value': -1}, 'num_beams': {'desc': None, 'value': 1}, 'ray_scope': {'desc': None, 'value': 'last'}, 'report_to': {'desc': None, 'value': ['wandb']}, 'typical_p': {'desc': None, 'value': 1}, 'use_cache': {'desc': None, 'value': False}, 'adam_beta1': {'desc': None, 'value': 0.9}, 'adam_beta2': {'desc': None, 'value': 0.95}, 'do_predict': {'desc': None, 'value': False}, 'eval_delay': {'desc': None, 'value': 0}, 'eval_steps': {'desc': None, 'value': None}, 'hidden_act': {'desc': None, 'value': 'silu'}, 'is_decoder': {'desc': None, 'value': False}, 'local_rank': {'desc': None, 'value': 0}, 'max_length': {'desc': None, 'value': 20}, 'min_length': {'desc': None, 'value': 0}, 'model_type': {'desc': None, 'value': 'llama'}, 'optim_args': {'desc': None, 'value': None}, 'output_dir': {'desc': None, 'value': '/lid/home/saydalie/multimodal_cot/models/SEED_trained/seed-llama-8b-GRPO-resq'}, 'past_index': {'desc': None, 'value': -1}, 'rope_theta': {'desc': None, 'value': 10000}, 'save_steps': {'desc': None, 'value': 0.05}, 'vllm_dtype': {'desc': None, 'value': 'auto'}, 'vocab_size': {'desc': None, 'value': 40194}, 'ddp_backend': {'desc': None, 'value': None}, 'ddp_timeout': {'desc': None, 'value': 1800}, 'fsdp_config': {'desc': None, 'value': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}}, 'hidden_size': {'desc': None, 'value': 4096}, 'label_names': {'desc': None, 'value': None}, 'logging_dir': {'desc': None, 'value': '/lid/home/saydalie/multimodal_cot/models/SEED_trained/seed-llama-8b-GRPO-resq/runs/Mar21_18-05-47_train-0-3'}, 'peft_config': {'desc': None, 'value': {'default': {'r': 16, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'loftq_config': {}, 'lora_dropout': 0.05, 'rank_pattern': {}, 'alpha_pattern': {}, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['up_proj', 'down_proj', 'k_proj', 'gate_proj', 'v_proj', 'o_proj', 'q_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': ['embed_tokens', 'lm_head', 'input_layernorm', 'post_attention_layernorm', 'norm'], 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': '/lid/home/saydalie/multimodal_cot/SEED/checkpoints/seed-llama-8b-sft-comm', 'trainable_token_indices': None}}}, 'push_to_hub': {'desc': None, 'value': False}, 'return_dict': {'desc': None, 'value': True}, 'temperature': {'desc': None, 'value': 0.9}, 'torch_dtype': {'desc': None, 'value': 'float32'}, 'torchdynamo': {'desc': None, 'value': None}, 'torchscript': {'desc': None, 'value': False}, 'vllm_device': {'desc': None, 'value': 'auto'}, 'adam_epsilon': {'desc': None, 'value': 1e-05}, 'bos_token_id': {'desc': None, 'value': 0}, 'disable_tqdm': {'desc': None, 'value': False}, 'eos_token_id': {'desc': None, 'value': 1}, 'fp16_backend': {'desc': None, 'value': 'auto'}, 'hub_model_id': {'desc': None, 'value': None}, 'hub_strategy': {'desc': None, 'value': 'every_save'}, 'pad_token_id': {'desc': None, 'value': -1}, 'problem_type': {'desc': None, 'value': None}, 'pruned_heads': {'desc': None, 'value': {}}, 'rms_norm_eps': {'desc': None, 'value': 1e-06}, 'rope_scaling': {'desc': None, 'value': None}, 'sep_token_id': {'desc': None, 'value': None}, 'use_bfloat16': {'desc': None, 'value': False}, 'warmup_ratio': {'desc': None, 'value': 0.01}, 'warmup_steps': {'desc': None, 'value': 0}, 'weight_decay': {'desc': None, 'value': 0.05}, '_name_or_path': {'desc': None, 'value': '/lid/home/saydalie/multimodal_cot/SEED/checkpoints/seed-llama-8b-sft-comm'}, 'architectures': {'desc': None, 'value': ['LlamaForCausalLM']}, 'bad_words_ids': {'desc': None, 'value': None}, 'eval_on_start': {'desc': None, 'value': False}, 'eval_strategy': {'desc': None, 'value': 'no'}, 'jit_mode_eval': {'desc': None, 'value': False}, 'learning_rate': {'desc': None, 'value': 5e-07}, 'logging_steps': {'desc': None, 'value': 0.01}, 'max_grad_norm': {'desc': None, 'value': 1}, 'mp_parameters': {'desc': None, 'value': ''}, 'output_scores': {'desc': None, 'value': False}, 'save_strategy': {'desc': None, 'value': 'steps'}, 'split_batches': {'desc': None, 'value': None}, 'torch_compile': {'desc': None, 'value': False}, 'tpu_num_cores': {'desc': None, 'value': None}, 'attention_bias': {'desc': None, 'value': False}, 'bf16_full_eval': {'desc': None, 'value': False}, 'early_stopping': {'desc': None, 'value': False}, 'fp16_full_eval': {'desc': None, 'value': False}, 'fp16_opt_level': {'desc': None, 'value': 'O1'}, 'length_penalty': {'desc': None, 'value': 1}, 'pretraining_tp': {'desc': None, 'value': 1}, 'reward_weights': {'desc': None, 'value': None}, 'sync_ref_model': {'desc': None, 'value': False}, 'tf_legacy_loss': {'desc': None, 'value': False}, 'use_mps_device': {'desc': None, 'value': False}, 'finetuning_task': {'desc': None, 'value': None}, 'group_by_length': {'desc': None, 'value': False}, 'hub_always_push': {'desc': None, 'value': False}, 'log_completions': {'desc': None, 'value': False}, 'num_beam_groups': {'desc': None, 'value': 1}, 'num_generations': {'desc': None, 'value': 8}, 'save_only_model': {'desc': None, 'value': False}, 'suppress_tokens': {'desc': None, 'value': None}, 'tokenizer_class': {'desc': None, 'value': None}, 'dispatch_batches': {'desc': None, 'value': None}, 'full_determinism': {'desc': None, 'value': False}, 'hub_private_repo': {'desc': None, 'value': None}, 'ignore_data_skip': {'desc': None, 'value': False}, 'log_on_each_node': {'desc': None, 'value': True}, 'logging_strategy': {'desc': None, 'value': 'steps'}, 'num_train_epochs': {'desc': None, 'value': 10}, 'save_safetensors': {'desc': None, 'value': True}, 'save_total_limit': {'desc': None, 'value': None}, 'use_liger_kernel': {'desc': None, 'value': False}, 'attention_dropout': {'desc': None, 'value': 0}, 'ddp_bucket_cap_mb': {'desc': None, 'value': None}, 'diversity_penalty': {'desc': None, 'value': 0}, 'greater_is_better': {'desc': None, 'value': None}, 'initializer_range': {'desc': None, 'value': 0.02}, 'intermediate_size': {'desc': None, 'value': 11008}, 'log_level_replica': {'desc': None, 'value': 'warning'}, 'lr_scheduler_type': {'desc': None, 'value': 'cosine'}, 'max_prompt_length': {'desc': None, 'value': 512}, 'model_init_kwargs': {'desc': None, 'value': None}, 'num_hidden_layers': {'desc': None, 'value': 32}, 'output_attentions': {'desc': None, 'value': False}, 'push_to_hub_token': {'desc': None, 'value': '<PUSH_TO_HUB_TOKEN>'}, 'save_on_each_node': {'desc': None, 'value': False}, 'tpu_metrics_debug': {'desc': None, 'value': False}, 'accelerator_config': {'desc': None, 'value': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}}, 'batch_eval_metrics': {'desc': None, 'value': False}, 'is_encoder_decoder': {'desc': None, 'value': False}, 'length_column_name': {'desc': None, 'value': 'length'}, 'logging_first_step': {'desc': None, 'value': False}, 'repetition_penalty': {'desc': None, 'value': 1}, 'torch_compile_mode': {'desc': None, 'value': None}, 'vllm_max_model_len': {'desc': None, 'value': None}, 'add_cross_attention': {'desc': None, 'value': False}, 'evaluation_strategy': {'desc': None, 'value': None}, 'forced_bos_token_id': {'desc': None, 'value': None}, 'forced_eos_token_id': {'desc': None, 'value': None}, 'fsdp_min_num_params': {'desc': None, 'value': 0}, 'include_for_metrics': {'desc': None, 'value': []}, 'lr_scheduler_kwargs': {'desc': None, 'value': {}}, 'max_sequence_length': {'desc': None, 'value': 2048}, 'neftune_noise_alpha': {'desc': None, 'value': None}, 'num_attention_heads': {'desc': None, 'value': 32}, 'num_key_value_heads': {'desc': None, 'value': 32}, 'skip_memory_metrics': {'desc': None, 'value': True}, 'tie_encoder_decoder': {'desc': None, 'value': False}, 'tie_word_embeddings': {'desc': None, 'value': False}, 'auto_find_batch_size': {'desc': None, 'value': False}, 'dataloader_drop_last': {'desc': None, 'value': False}, 'model/num_parameters': {'desc': None, 'value': 7175053312}, 'no_repeat_ngram_size': {'desc': None, 'value': 0}, 'num_return_sequences': {'desc': None, 'value': 1}, 'optim_target_modules': {'desc': None, 'value': None}, 'output_hidden_states': {'desc': None, 'value': False}, 'overwrite_output_dir': {'desc': None, 'value': False}, 'prediction_loss_only': {'desc': None, 'value': False}, 'push_to_hub_model_id': {'desc': None, 'value': None}, 'ref_model_sync_steps': {'desc': None, 'value': 64}, 'task_specific_params': {'desc': None, 'value': None}, 'transformers_version': {'desc': None, 'value': '4.49.0'}, 'begin_suppress_tokens': {'desc': None, 'value': None}, 'dataloader_pin_memory': {'desc': None, 'value': True}, 'ddp_broadcast_buffers': {'desc': None, 'value': None}, 'max_completion_length': {'desc': None, 'value': 1024}, 'metric_for_best_model': {'desc': None, 'value': None}, 'ref_model_mixup_alpha': {'desc': None, 'value': 0.9}, 'remove_invalid_values': {'desc': None, 'value': False}, 'remove_unused_columns': {'desc': None, 'value': False}, 'torch_compile_backend': {'desc': None, 'value': None}, 'dataloader_num_workers': {'desc': None, 'value': 8}, 'decoder_start_token_id': {'desc': None, 'value': None}, 'eval_do_concat_batches': {'desc': None, 'value': True}, 'eval_use_gather_object': {'desc': None, 'value': False}, 'gradient_checkpointing': {'desc': None, 'value': False}, 'half_precision_backend': {'desc': None, 'value': 'auto'}, 'label_smoothing_factor': {'desc': None, 'value': 0}, 'load_best_model_at_end': {'desc': None, 'value': False}, 'logging_nan_inf_filter': {'desc': None, 'value': 'no'}, 'resume_from_checkpoint': {'desc': None, 'value': None}, 'chunk_size_feed_forward': {'desc': None, 'value': 0}, 'eval_accumulation_steps': {'desc': None, 'value': None}, 'max_position_embeddings': {'desc': None, 'value': 2048}, 'per_gpu_eval_batch_size': {'desc': None, 'value': None}, 'return_dict_in_generate': {'desc': None, 'value': False}, 'torch_empty_cache_steps': {'desc': None, 'value': None}, 'per_gpu_train_batch_size': {'desc': None, 'value': None}, 'push_to_hub_organization': {'desc': None, 'value': None}, 'ds3_gather_for_generation': {'desc': None, 'value': True}, 'include_tokens_per_second': {'desc': None, 'value': False}, 'dataloader_prefetch_factor': {'desc': None, 'value': None}, 'ddp_find_unused_parameters': {'desc': None, 'value': None}, 'include_inputs_for_metrics': {'desc': None, 'value': False}, 'per_device_eval_batch_size': {'desc': None, 'value': 8}, 'use_legacy_prediction_loop': {'desc': None, 'value': False}, 'cross_attention_hidden_size': {'desc': None, 'value': None}, 'gradient_accumulation_steps': {'desc': None, 'value': 4}, 'per_device_train_batch_size': {'desc': None, 'value': 16}, 'vllm_gpu_memory_utilization': {'desc': None, 'value': 0.9}, '_attn_implementation_autoset': {'desc': None, 'value': True}, 'encoder_no_repeat_ngram_size': {'desc': None, 'value': 0}, 'average_tokens_across_devices': {'desc': None, 'value': False}, 'dataloader_persistent_workers': {'desc': None, 'value': False}, 'gradient_checkpointing_kwargs': {'desc': None, 'value': None}, 'include_num_input_tokens_seen': {'desc': None, 'value': False}, 'exponential_decay_length_penalty': {'desc': None, 'value': None}, 'fsdp_transformer_layer_cls_to_wrap': {'desc': None, 'value': None}, 'restore_callback_states_from_checkpoint': {'desc': None, 'value': False}},tags=[])
2025-03-21 18:13:54,273 INFO    SenderThread:692 [dir_watcher.py:__init__():211] watching files in: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_181353-seed-llama-8b-GRPO-resq/files
2025-03-21 18:13:54,273 INFO    SenderThread:692 [sender.py:_start_run_threads():1136] run started: seed-llama-8b-GRPO-resq with start time 1742580701.701296
2025-03-21 18:13:54,275 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: summary_record
2025-03-21 18:13:54,276 INFO    SenderThread:692 [sender.py:_save_file():1403] saving file wandb-summary.json with policy end
2025-03-21 18:13:54,281 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: check_version
2025-03-21 18:13:54,281 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: check_version
2025-03-21 18:13:54,355 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: run_start
2025-03-21 18:13:54,372 DEBUG   HandlerThread:692 [system_info.py:__init__():27] System info init
2025-03-21 18:13:54,372 DEBUG   HandlerThread:692 [system_info.py:__init__():42] System info init done
2025-03-21 18:13:54,372 INFO    HandlerThread:692 [system_monitor.py:start():194] Starting system monitor
2025-03-21 18:13:54,372 INFO    SystemMonitor:692 [system_monitor.py:_start():158] Starting system asset monitoring threads
2025-03-21 18:13:54,373 INFO    SystemMonitor:692 [interfaces.py:start():190] Started cpu monitoring
2025-03-21 18:13:54,373 INFO    SystemMonitor:692 [interfaces.py:start():190] Started disk monitoring
2025-03-21 18:13:54,374 INFO    SystemMonitor:692 [interfaces.py:start():190] Started gpu monitoring
2025-03-21 18:13:54,375 INFO    SystemMonitor:692 [interfaces.py:start():190] Started memory monitoring
2025-03-21 18:13:54,375 INFO    SystemMonitor:692 [interfaces.py:start():190] Started network monitoring
2025-03-21 18:13:54,382 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: python_packages
2025-03-21 18:13:54,383 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: python_packages
2025-03-21 18:13:54,424 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: stop_status
2025-03-21 18:13:54,424 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: internal_messages
2025-03-21 18:13:54,424 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: stop_status
2025-03-21 18:13:54,638 DEBUG   SenderThread:692 [sender.py:send():382] send: telemetry
2025-03-21 18:13:54,638 DEBUG   SenderThread:692 [sender.py:send():382] send: config
2025-03-21 18:13:54,639 DEBUG   SenderThread:692 [sender.py:send():382] send: metric
2025-03-21 18:13:54,639 DEBUG   SenderThread:692 [sender.py:send():382] send: telemetry
2025-03-21 18:13:54,639 DEBUG   SenderThread:692 [sender.py:send():382] send: metric
2025-03-21 18:13:54,639 WARNING SenderThread:692 [sender.py:send_metric():1354] Seen metric with glob (shouldn't happen)
2025-03-21 18:13:54,639 DEBUG   SenderThread:692 [sender.py:send():382] send: telemetry
2025-03-21 18:13:54,640 DEBUG   SenderThread:692 [sender.py:send():382] send: telemetry
2025-03-21 18:13:54,640 DEBUG   SenderThread:692 [sender.py:send():382] send: config
2025-03-21 18:13:55,276 INFO    Thread-12 :692 [dir_watcher.py:_on_file_created():271] file/dir created: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_181353-seed-llama-8b-GRPO-resq/files/requirements.txt
2025-03-21 18:13:55,277 INFO    Thread-12 :692 [dir_watcher.py:_on_file_created():271] file/dir created: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_181353-seed-llama-8b-GRPO-resq/files/wandb-summary.json
2025-03-21 18:13:55,277 INFO    Thread-12 :692 [dir_watcher.py:_on_file_created():271] file/dir created: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_181353-seed-llama-8b-GRPO-resq/files/output.log
2025-03-21 18:13:57,277 INFO    Thread-12 :692 [dir_watcher.py:_on_file_modified():288] file/dir modified: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_181353-seed-llama-8b-GRPO-resq/files/output.log
2025-03-21 18:13:58,642 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:14:03,642 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:14:08,643 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:14:09,384 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: stop_status
2025-03-21 18:14:09,384 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: stop_status
2025-03-21 18:14:09,431 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: internal_messages
2025-03-21 18:14:14,576 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:14:19,577 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:14:24,383 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: stop_status
2025-03-21 18:14:24,384 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: stop_status
2025-03-21 18:14:24,427 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: internal_messages
2025-03-21 18:14:24,588 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:14:25,295 INFO    Thread-12 :692 [dir_watcher.py:_on_file_modified():288] file/dir modified: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_181353-seed-llama-8b-GRPO-resq/files/config.yaml
2025-03-21 18:14:29,814 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:14:34,814 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:14:39,383 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: stop_status
2025-03-21 18:14:39,383 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: stop_status
2025-03-21 18:14:39,423 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: internal_messages
2025-03-21 18:14:40,572 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:14:45,573 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:14:50,574 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:14:54,375 DEBUG   SystemMonitor:692 [system_monitor.py:_start():172] Starting system metrics aggregation loop
2025-03-21 18:14:54,377 DEBUG   SenderThread:692 [sender.py:send():382] send: stats
2025-03-21 18:14:54,383 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: stop_status
2025-03-21 18:14:54,383 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: stop_status
2025-03-21 18:14:54,424 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: internal_messages
2025-03-21 18:14:55,627 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:15:00,627 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:15:02,701 DEBUG   SenderThread:692 [sender.py:send():382] send: exit
2025-03-21 18:15:02,701 INFO    SenderThread:692 [sender.py:send_exit():589] handling exit code: 1
2025-03-21 18:15:02,702 INFO    SenderThread:692 [sender.py:send_exit():591] handling runtime: 137
2025-03-21 18:15:02,704 INFO    SenderThread:692 [sender.py:_save_file():1403] saving file wandb-summary.json with policy end
2025-03-21 18:15:02,704 INFO    SenderThread:692 [sender.py:send_exit():597] send defer
2025-03-21 18:15:02,705 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:15:02,705 INFO    HandlerThread:692 [handler.py:handle_request_defer():172] handle defer: 0
2025-03-21 18:15:02,705 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: defer
2025-03-21 18:15:02,705 INFO    SenderThread:692 [sender.py:send_request_defer():613] handle sender defer: 0
2025-03-21 18:15:02,705 INFO    SenderThread:692 [sender.py:transition_state():617] send defer: 1
2025-03-21 18:15:02,705 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:15:02,705 INFO    HandlerThread:692 [handler.py:handle_request_defer():172] handle defer: 1
2025-03-21 18:15:02,705 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: defer
2025-03-21 18:15:02,705 INFO    SenderThread:692 [sender.py:send_request_defer():613] handle sender defer: 1
2025-03-21 18:15:02,705 INFO    SenderThread:692 [sender.py:transition_state():617] send defer: 2
2025-03-21 18:15:02,706 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:15:02,706 INFO    HandlerThread:692 [handler.py:handle_request_defer():172] handle defer: 2
2025-03-21 18:15:02,706 INFO    HandlerThread:692 [system_monitor.py:finish():203] Stopping system monitor
2025-03-21 18:15:02,706 INFO    HandlerThread:692 [interfaces.py:finish():202] Joined cpu monitor
2025-03-21 18:15:02,707 INFO    HandlerThread:692 [interfaces.py:finish():202] Joined disk monitor
2025-03-21 18:15:02,707 DEBUG   SystemMonitor:692 [system_monitor.py:_start():179] Finished system metrics aggregation loop
2025-03-21 18:15:02,707 DEBUG   SystemMonitor:692 [system_monitor.py:_start():183] Publishing last batch of metrics
2025-03-21 18:15:02,831 INFO    HandlerThread:692 [interfaces.py:finish():202] Joined gpu monitor
2025-03-21 18:15:02,831 INFO    HandlerThread:692 [interfaces.py:finish():202] Joined memory monitor
2025-03-21 18:15:02,831 INFO    HandlerThread:692 [interfaces.py:finish():202] Joined network monitor
2025-03-21 18:15:02,831 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: defer
2025-03-21 18:15:02,832 INFO    SenderThread:692 [sender.py:send_request_defer():613] handle sender defer: 2
2025-03-21 18:15:02,832 INFO    SenderThread:692 [sender.py:transition_state():617] send defer: 3
2025-03-21 18:15:02,832 DEBUG   SenderThread:692 [sender.py:send():382] send: stats
2025-03-21 18:15:02,833 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:15:02,833 INFO    HandlerThread:692 [handler.py:handle_request_defer():172] handle defer: 3
2025-03-21 18:15:02,833 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: defer
2025-03-21 18:15:02,833 INFO    SenderThread:692 [sender.py:send_request_defer():613] handle sender defer: 3
2025-03-21 18:15:02,833 INFO    SenderThread:692 [sender.py:transition_state():617] send defer: 4
2025-03-21 18:15:02,834 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:15:02,834 INFO    HandlerThread:692 [handler.py:handle_request_defer():172] handle defer: 4
2025-03-21 18:15:02,834 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: defer
2025-03-21 18:15:02,834 INFO    SenderThread:692 [sender.py:send_request_defer():613] handle sender defer: 4
2025-03-21 18:15:02,834 INFO    SenderThread:692 [sender.py:transition_state():617] send defer: 5
2025-03-21 18:15:02,834 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:15:02,834 INFO    HandlerThread:692 [handler.py:handle_request_defer():172] handle defer: 5
2025-03-21 18:15:02,834 DEBUG   SenderThread:692 [sender.py:send():382] send: summary
2025-03-21 18:15:02,836 INFO    SenderThread:692 [sender.py:_save_file():1403] saving file wandb-summary.json with policy end
2025-03-21 18:15:02,837 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: defer
2025-03-21 18:15:02,837 INFO    SenderThread:692 [sender.py:send_request_defer():613] handle sender defer: 5
2025-03-21 18:15:02,837 INFO    SenderThread:692 [sender.py:transition_state():617] send defer: 6
2025-03-21 18:15:02,837 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:15:02,837 INFO    HandlerThread:692 [handler.py:handle_request_defer():172] handle defer: 6
2025-03-21 18:15:02,837 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: defer
2025-03-21 18:15:02,837 INFO    SenderThread:692 [sender.py:send_request_defer():613] handle sender defer: 6
2025-03-21 18:15:02,837 INFO    SenderThread:692 [sender.py:transition_state():617] send defer: 7
2025-03-21 18:15:02,838 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:15:02,838 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:15:02,838 INFO    HandlerThread:692 [handler.py:handle_request_defer():172] handle defer: 7
2025-03-21 18:15:02,838 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: defer
2025-03-21 18:15:02,838 INFO    SenderThread:692 [sender.py:send_request_defer():613] handle sender defer: 7
2025-03-21 18:15:03,320 INFO    Thread-12 :692 [dir_watcher.py:_on_file_modified():288] file/dir modified: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_181353-seed-llama-8b-GRPO-resq/files/wandb-summary.json
2025-03-21 18:15:03,700 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: poll_exit
2025-03-21 18:15:04,731 INFO    SenderThread:692 [sender.py:transition_state():617] send defer: 8
2025-03-21 18:15:04,731 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: poll_exit
2025-03-21 18:15:04,732 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:15:04,732 INFO    HandlerThread:692 [handler.py:handle_request_defer():172] handle defer: 8
2025-03-21 18:15:04,732 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: defer
2025-03-21 18:15:04,732 INFO    SenderThread:692 [sender.py:send_request_defer():613] handle sender defer: 8
2025-03-21 18:15:04,732 INFO    SenderThread:692 [job_builder.py:build():296] Attempting to build job artifact
2025-03-21 18:15:04,733 INFO    SenderThread:692 [sender.py:transition_state():617] send defer: 9
2025-03-21 18:15:04,733 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:15:04,733 INFO    HandlerThread:692 [handler.py:handle_request_defer():172] handle defer: 9
2025-03-21 18:15:04,733 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: defer
2025-03-21 18:15:04,733 INFO    SenderThread:692 [sender.py:send_request_defer():613] handle sender defer: 9
2025-03-21 18:15:04,733 INFO    SenderThread:692 [dir_watcher.py:finish():358] shutting down directory watcher
2025-03-21 18:15:05,322 INFO    SenderThread:692 [dir_watcher.py:_on_file_modified():288] file/dir modified: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_181353-seed-llama-8b-GRPO-resq/files/output.log
2025-03-21 18:15:05,322 INFO    SenderThread:692 [dir_watcher.py:finish():388] scan: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_181353-seed-llama-8b-GRPO-resq/files
2025-03-21 18:15:05,322 INFO    SenderThread:692 [dir_watcher.py:finish():402] scan save: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_181353-seed-llama-8b-GRPO-resq/files/config.yaml config.yaml
2025-03-21 18:15:05,322 INFO    SenderThread:692 [dir_watcher.py:finish():402] scan save: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_181353-seed-llama-8b-GRPO-resq/files/wandb-summary.json wandb-summary.json
2025-03-21 18:15:05,323 INFO    SenderThread:692 [dir_watcher.py:finish():402] scan save: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_181353-seed-llama-8b-GRPO-resq/files/requirements.txt requirements.txt
2025-03-21 18:15:05,327 INFO    SenderThread:692 [dir_watcher.py:finish():402] scan save: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_181353-seed-llama-8b-GRPO-resq/files/output.log output.log
2025-03-21 18:15:05,328 INFO    SenderThread:692 [sender.py:transition_state():617] send defer: 10
2025-03-21 18:15:05,329 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:15:05,329 INFO    HandlerThread:692 [handler.py:handle_request_defer():172] handle defer: 10
2025-03-21 18:15:05,330 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: defer
2025-03-21 18:15:05,330 INFO    SenderThread:692 [sender.py:send_request_defer():613] handle sender defer: 10
2025-03-21 18:15:05,330 INFO    SenderThread:692 [file_pusher.py:finish():175] shutting down file pusher
2025-03-21 18:15:05,701 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: poll_exit
2025-03-21 18:15:05,702 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: poll_exit
2025-03-21 18:15:05,954 INFO    wandb-upload_0:692 [upload_job.py:push():131] Uploaded file /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_181353-seed-llama-8b-GRPO-resq/files/config.yaml
2025-03-21 18:15:05,955 INFO    wandb-upload_1:692 [upload_job.py:push():131] Uploaded file /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_181353-seed-llama-8b-GRPO-resq/files/wandb-summary.json
2025-03-21 18:15:05,955 INFO    wandb-upload_2:692 [upload_job.py:push():131] Uploaded file /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_181353-seed-llama-8b-GRPO-resq/files/requirements.txt
2025-03-21 18:15:05,986 INFO    wandb-upload_3:692 [upload_job.py:push():131] Uploaded file /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_181353-seed-llama-8b-GRPO-resq/files/output.log
2025-03-21 18:15:06,187 INFO    Thread-11 (_thread_body):692 [sender.py:transition_state():617] send defer: 11
2025-03-21 18:15:06,187 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:15:06,187 INFO    HandlerThread:692 [handler.py:handle_request_defer():172] handle defer: 11
2025-03-21 18:15:06,188 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: defer
2025-03-21 18:15:06,188 INFO    SenderThread:692 [sender.py:send_request_defer():613] handle sender defer: 11
2025-03-21 18:15:06,188 INFO    SenderThread:692 [file_pusher.py:join():181] waiting for file pusher
2025-03-21 18:15:06,188 INFO    SenderThread:692 [sender.py:transition_state():617] send defer: 12
2025-03-21 18:15:06,188 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:15:06,188 INFO    HandlerThread:692 [handler.py:handle_request_defer():172] handle defer: 12
2025-03-21 18:15:06,188 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: defer
2025-03-21 18:15:06,188 INFO    SenderThread:692 [sender.py:send_request_defer():613] handle sender defer: 12
2025-03-21 18:15:06,188 INFO    SenderThread:692 [file_stream.py:finish():595] file stream finish called
2025-03-21 18:15:06,358 INFO    SenderThread:692 [file_stream.py:finish():599] file stream finish is done
2025-03-21 18:15:06,358 INFO    SenderThread:692 [sender.py:transition_state():617] send defer: 13
2025-03-21 18:15:06,358 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:15:06,358 INFO    HandlerThread:692 [handler.py:handle_request_defer():172] handle defer: 13
2025-03-21 18:15:06,359 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: defer
2025-03-21 18:15:06,359 INFO    SenderThread:692 [sender.py:send_request_defer():613] handle sender defer: 13
2025-03-21 18:15:06,359 INFO    SenderThread:692 [sender.py:transition_state():617] send defer: 14
2025-03-21 18:15:06,359 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:15:06,359 INFO    HandlerThread:692 [handler.py:handle_request_defer():172] handle defer: 14
2025-03-21 18:15:06,359 DEBUG   SenderThread:692 [sender.py:send():382] send: final
2025-03-21 18:15:06,359 DEBUG   SenderThread:692 [sender.py:send():382] send: footer
2025-03-21 18:15:06,359 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: defer
2025-03-21 18:15:06,359 INFO    SenderThread:692 [sender.py:send_request_defer():613] handle sender defer: 14
2025-03-21 18:15:06,360 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: poll_exit
2025-03-21 18:15:06,360 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: poll_exit
2025-03-21 18:15:06,360 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: poll_exit
2025-03-21 18:15:06,360 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: poll_exit
2025-03-21 18:15:06,361 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: server_info
2025-03-21 18:15:06,361 DEBUG   SenderThread:692 [sender.py:send_request():409] send_request: server_info
2025-03-21 18:15:06,363 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: get_summary
2025-03-21 18:15:06,363 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: sampled_history
2025-03-21 18:15:06,363 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: internal_messages
2025-03-21 18:15:06,363 DEBUG   HandlerThread:692 [handler.py:handle_request():146] handle_request: job_info
2025-03-21 18:15:06,387 WARNING StreamThr :692 [internal.py:is_dead():414] Internal process exiting, parent pid 385 disappeared
2025-03-21 18:15:06,387 ERROR   StreamThr :692 [internal.py:wandb_internal():152] Internal process shutdown.
2025-03-21 18:15:06,522 INFO    SenderThread:692 [sender.py:finish():1572] shutting down sender
2025-03-21 18:15:06,522 INFO    SenderThread:692 [file_pusher.py:finish():175] shutting down file pusher
2025-03-21 18:15:06,522 INFO    SenderThread:692 [file_pusher.py:join():181] waiting for file pusher
