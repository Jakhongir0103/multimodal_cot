2025-03-21 18:05:59,623 INFO    StreamThr :704 [internal.py:wandb_internal():86] W&B internal server running at pid: 704, started at: 2025-03-21 18:05:59.621506
2025-03-21 18:05:59,624 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: status
2025-03-21 18:05:59,626 INFO    WriterThread:704 [datastore.py:open_for_write():87] open: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_180559-seed-llama-8b-GRPO-resq/run-seed-llama-8b-GRPO-resq.wandb
2025-03-21 18:05:59,627 DEBUG   SenderThread:704 [sender.py:send():382] send: header
2025-03-21 18:05:59,644 DEBUG   SenderThread:704 [sender.py:send():382] send: run
2025-03-21 18:05:59,648 INFO    SenderThread:704 [sender.py:_maybe_setup_resume():763] checking resume status for jakhongir-saydaliev-epfl/multimodal_cot/seed-llama-8b-GRPO-resq
2025-03-21 18:06:00,123 INFO    SenderThread:704 [sender.py:_maybe_setup_resume():841] configured resuming with: ResumeState(resumed=True,step=0,history=0,events=1,output=1,runtime=60.80912,wandb_runtime=None,summary={},config={'beta': {'desc': None, 'value': 0.04}, 'bf16': {'desc': None, 'value': True}, 'fp16': {'desc': None, 'value': False}, 'fsdp': {'desc': None, 'value': []}, 'seed': {'desc': None, 'value': 42}, 'tf32': {'desc': None, 'value': None}, 'debug': {'desc': None, 'value': []}, 'optim': {'desc': None, 'value': 'adamw_torch'}, 'top_k': {'desc': None, 'value': 50}, 'top_p': {'desc': None, 'value': 1}, '_wandb': {'desc': None, 'value': {'m': [{'1': 'train/global_step', '6': [3]}], 't': {'1': [1, 11, 41, 49, 51, 55, 63, 71, 83, 84, 98], '2': [1, 11, 41, 49, 51, 55, 63, 71, 83, 84, 98], '3': [7, 13, 19, 23], '4': '3.10.12', '5': '0.16.2', '6': '4.49.0', '8': [5], '9': {'1': 'transformers_trainer'}, '13': 'linux-x86_64'}, 'framework': 'huggingface', 'start_time': 1742579941.528577, 'cli_version': '0.16.2', 'is_jupyter_run': False, 'python_version': '3.10.12', 'is_kaggle_kernel': False, 'huggingface_version': '4.49.0'}}, 'prefix': {'desc': None, 'value': None}, 'do_eval': {'desc': None, 'value': False}, 'no_cuda': {'desc': None, 'value': False}, 'use_cpu': {'desc': None, 'value': False}, 'do_train': {'desc': None, 'value': False}, 'head_dim': {'desc': None, 'value': 128}, 'id2label': {'desc': None, 'value': {'0': 'LABEL_0', '1': 'LABEL_1'}}, 'label2id': {'desc': None, 'value': {'LABEL_0': 0, 'LABEL_1': 1}}, 'mlp_bias': {'desc': None, 'value': False}, 'run_name': {'desc': None, 'value': 'seed-llama-8b-GRPO-resq'}, 'use_ipex': {'desc': None, 'value': False}, 'use_vllm': {'desc': None, 'value': False}, 'adafactor': {'desc': None, 'value': False}, 'data_seed': {'desc': None, 'value': None}, 'deepspeed': {'desc': None, 'value': '/lid/home/saydalie/multimodal_cot/SEED/MultiModalLLM/configs/deepspeed/stage2_bf16.json'}, 'do_sample': {'desc': None, 'value': False}, 'hub_token': {'desc': None, 'value': '<HUB_TOKEN>'}, 'log_level': {'desc': None, 'value': 'info'}, 'max_steps': {'desc': None, 'value': -1}, 'num_beams': {'desc': None, 'value': 1}, 'ray_scope': {'desc': None, 'value': 'last'}, 'report_to': {'desc': None, 'value': ['wandb']}, 'typical_p': {'desc': None, 'value': 1}, 'use_cache': {'desc': None, 'value': False}, 'adam_beta1': {'desc': None, 'value': 0.9}, 'adam_beta2': {'desc': None, 'value': 0.95}, 'do_predict': {'desc': None, 'value': False}, 'eval_delay': {'desc': None, 'value': 0}, 'eval_steps': {'desc': None, 'value': None}, 'hidden_act': {'desc': None, 'value': 'silu'}, 'is_decoder': {'desc': None, 'value': False}, 'local_rank': {'desc': None, 'value': 0}, 'max_length': {'desc': None, 'value': 20}, 'min_length': {'desc': None, 'value': 0}, 'model_type': {'desc': None, 'value': 'llama'}, 'optim_args': {'desc': None, 'value': None}, 'output_dir': {'desc': None, 'value': '/lid/home/saydalie/multimodal_cot/models/SEED_trained/seed-llama-8b-GRPO-resq'}, 'past_index': {'desc': None, 'value': -1}, 'rope_theta': {'desc': None, 'value': 10000}, 'save_steps': {'desc': None, 'value': 0.05}, 'vllm_dtype': {'desc': None, 'value': 'auto'}, 'vocab_size': {'desc': None, 'value': 40194}, 'ddp_backend': {'desc': None, 'value': None}, 'ddp_timeout': {'desc': None, 'value': 1800}, 'fsdp_config': {'desc': None, 'value': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}}, 'hidden_size': {'desc': None, 'value': 4096}, 'label_names': {'desc': None, 'value': None}, 'logging_dir': {'desc': None, 'value': '/lid/home/saydalie/multimodal_cot/models/SEED_trained/seed-llama-8b-GRPO-resq/runs/Mar21_17-58-50_train-0-2'}, 'peft_config': {'desc': None, 'value': {'default': {'r': 16, 'bias': 'none', 'revision': None, 'use_dora': False, 'lora_bias': False, 'peft_type': 'LORA', 'task_type': 'CAUSAL_LM', 'eva_config': None, 'lora_alpha': 32, 'use_rslora': False, 'auto_mapping': None, 'corda_config': None, 'loftq_config': {}, 'lora_dropout': 0.05, 'rank_pattern': {}, 'alpha_pattern': {}, 'megatron_core': 'megatron.core', 'fan_in_fan_out': False, 'inference_mode': False, 'layers_pattern': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'target_modules': ['up_proj', 'q_proj', 'down_proj', 'v_proj', 'gate_proj', 'o_proj', 'k_proj'], 'exclude_modules': None, 'megatron_config': None, 'modules_to_save': ['embed_tokens', 'lm_head', 'input_layernorm', 'post_attention_layernorm', 'norm'], 'init_lora_weights': True, 'layer_replication': None, 'layers_to_transform': None, 'base_model_name_or_path': '/lid/home/saydalie/multimodal_cot/SEED/checkpoints/seed-llama-8b-sft-comm', 'trainable_token_indices': None}}}, 'push_to_hub': {'desc': None, 'value': False}, 'return_dict': {'desc': None, 'value': True}, 'temperature': {'desc': None, 'value': 0.9}, 'torch_dtype': {'desc': None, 'value': 'float32'}, 'torchdynamo': {'desc': None, 'value': None}, 'torchscript': {'desc': None, 'value': False}, 'vllm_device': {'desc': None, 'value': 'auto'}, 'adam_epsilon': {'desc': None, 'value': 1e-05}, 'bos_token_id': {'desc': None, 'value': 0}, 'disable_tqdm': {'desc': None, 'value': False}, 'eos_token_id': {'desc': None, 'value': 1}, 'fp16_backend': {'desc': None, 'value': 'auto'}, 'hub_model_id': {'desc': None, 'value': None}, 'hub_strategy': {'desc': None, 'value': 'every_save'}, 'pad_token_id': {'desc': None, 'value': -1}, 'problem_type': {'desc': None, 'value': None}, 'pruned_heads': {'desc': None, 'value': {}}, 'rms_norm_eps': {'desc': None, 'value': 1e-06}, 'rope_scaling': {'desc': None, 'value': None}, 'sep_token_id': {'desc': None, 'value': None}, 'use_bfloat16': {'desc': None, 'value': False}, 'warmup_ratio': {'desc': None, 'value': 0.01}, 'warmup_steps': {'desc': None, 'value': 0}, 'weight_decay': {'desc': None, 'value': 0.05}, '_name_or_path': {'desc': None, 'value': '/lid/home/saydalie/multimodal_cot/SEED/checkpoints/seed-llama-8b-sft-comm'}, 'architectures': {'desc': None, 'value': ['LlamaForCausalLM']}, 'bad_words_ids': {'desc': None, 'value': None}, 'eval_on_start': {'desc': None, 'value': False}, 'eval_strategy': {'desc': None, 'value': 'no'}, 'jit_mode_eval': {'desc': None, 'value': False}, 'learning_rate': {'desc': None, 'value': 5e-07}, 'logging_steps': {'desc': None, 'value': 0.01}, 'max_grad_norm': {'desc': None, 'value': 1}, 'mp_parameters': {'desc': None, 'value': ''}, 'output_scores': {'desc': None, 'value': False}, 'save_strategy': {'desc': None, 'value': 'steps'}, 'split_batches': {'desc': None, 'value': None}, 'torch_compile': {'desc': None, 'value': False}, 'tpu_num_cores': {'desc': None, 'value': None}, 'attention_bias': {'desc': None, 'value': False}, 'bf16_full_eval': {'desc': None, 'value': False}, 'early_stopping': {'desc': None, 'value': False}, 'fp16_full_eval': {'desc': None, 'value': False}, 'fp16_opt_level': {'desc': None, 'value': 'O1'}, 'length_penalty': {'desc': None, 'value': 1}, 'pretraining_tp': {'desc': None, 'value': 1}, 'reward_weights': {'desc': None, 'value': None}, 'sync_ref_model': {'desc': None, 'value': False}, 'tf_legacy_loss': {'desc': None, 'value': False}, 'use_mps_device': {'desc': None, 'value': False}, 'finetuning_task': {'desc': None, 'value': None}, 'group_by_length': {'desc': None, 'value': False}, 'hub_always_push': {'desc': None, 'value': False}, 'log_completions': {'desc': None, 'value': False}, 'num_beam_groups': {'desc': None, 'value': 1}, 'num_generations': {'desc': None, 'value': 8}, 'save_only_model': {'desc': None, 'value': False}, 'suppress_tokens': {'desc': None, 'value': None}, 'tokenizer_class': {'desc': None, 'value': None}, 'dispatch_batches': {'desc': None, 'value': None}, 'full_determinism': {'desc': None, 'value': False}, 'hub_private_repo': {'desc': None, 'value': None}, 'ignore_data_skip': {'desc': None, 'value': False}, 'log_on_each_node': {'desc': None, 'value': True}, 'logging_strategy': {'desc': None, 'value': 'steps'}, 'num_train_epochs': {'desc': None, 'value': 10}, 'save_safetensors': {'desc': None, 'value': True}, 'save_total_limit': {'desc': None, 'value': None}, 'use_liger_kernel': {'desc': None, 'value': False}, 'attention_dropout': {'desc': None, 'value': 0}, 'ddp_bucket_cap_mb': {'desc': None, 'value': None}, 'diversity_penalty': {'desc': None, 'value': 0}, 'greater_is_better': {'desc': None, 'value': None}, 'initializer_range': {'desc': None, 'value': 0.02}, 'intermediate_size': {'desc': None, 'value': 11008}, 'log_level_replica': {'desc': None, 'value': 'warning'}, 'lr_scheduler_type': {'desc': None, 'value': 'cosine'}, 'max_prompt_length': {'desc': None, 'value': 512}, 'model_init_kwargs': {'desc': None, 'value': None}, 'num_hidden_layers': {'desc': None, 'value': 32}, 'output_attentions': {'desc': None, 'value': False}, 'push_to_hub_token': {'desc': None, 'value': '<PUSH_TO_HUB_TOKEN>'}, 'save_on_each_node': {'desc': None, 'value': False}, 'tpu_metrics_debug': {'desc': None, 'value': False}, 'accelerator_config': {'desc': None, 'value': {'even_batches': True, 'non_blocking': False, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}}, 'batch_eval_metrics': {'desc': None, 'value': False}, 'is_encoder_decoder': {'desc': None, 'value': False}, 'length_column_name': {'desc': None, 'value': 'length'}, 'logging_first_step': {'desc': None, 'value': False}, 'repetition_penalty': {'desc': None, 'value': 1}, 'torch_compile_mode': {'desc': None, 'value': None}, 'vllm_max_model_len': {'desc': None, 'value': None}, 'add_cross_attention': {'desc': None, 'value': False}, 'evaluation_strategy': {'desc': None, 'value': None}, 'forced_bos_token_id': {'desc': None, 'value': None}, 'forced_eos_token_id': {'desc': None, 'value': None}, 'fsdp_min_num_params': {'desc': None, 'value': 0}, 'include_for_metrics': {'desc': None, 'value': []}, 'lr_scheduler_kwargs': {'desc': None, 'value': {}}, 'max_sequence_length': {'desc': None, 'value': 2048}, 'neftune_noise_alpha': {'desc': None, 'value': None}, 'num_attention_heads': {'desc': None, 'value': 32}, 'num_key_value_heads': {'desc': None, 'value': 32}, 'skip_memory_metrics': {'desc': None, 'value': True}, 'tie_encoder_decoder': {'desc': None, 'value': False}, 'tie_word_embeddings': {'desc': None, 'value': False}, 'auto_find_batch_size': {'desc': None, 'value': False}, 'dataloader_drop_last': {'desc': None, 'value': False}, 'model/num_parameters': {'desc': None, 'value': 7175053312}, 'no_repeat_ngram_size': {'desc': None, 'value': 0}, 'num_return_sequences': {'desc': None, 'value': 1}, 'optim_target_modules': {'desc': None, 'value': None}, 'output_hidden_states': {'desc': None, 'value': False}, 'overwrite_output_dir': {'desc': None, 'value': False}, 'prediction_loss_only': {'desc': None, 'value': False}, 'push_to_hub_model_id': {'desc': None, 'value': None}, 'ref_model_sync_steps': {'desc': None, 'value': 64}, 'task_specific_params': {'desc': None, 'value': None}, 'transformers_version': {'desc': None, 'value': '4.49.0'}, 'begin_suppress_tokens': {'desc': None, 'value': None}, 'dataloader_pin_memory': {'desc': None, 'value': True}, 'ddp_broadcast_buffers': {'desc': None, 'value': None}, 'max_completion_length': {'desc': None, 'value': 1024}, 'metric_for_best_model': {'desc': None, 'value': None}, 'ref_model_mixup_alpha': {'desc': None, 'value': 0.9}, 'remove_invalid_values': {'desc': None, 'value': False}, 'remove_unused_columns': {'desc': None, 'value': False}, 'torch_compile_backend': {'desc': None, 'value': None}, 'dataloader_num_workers': {'desc': None, 'value': 8}, 'decoder_start_token_id': {'desc': None, 'value': None}, 'eval_do_concat_batches': {'desc': None, 'value': True}, 'eval_use_gather_object': {'desc': None, 'value': False}, 'gradient_checkpointing': {'desc': None, 'value': False}, 'half_precision_backend': {'desc': None, 'value': 'auto'}, 'label_smoothing_factor': {'desc': None, 'value': 0}, 'load_best_model_at_end': {'desc': None, 'value': False}, 'logging_nan_inf_filter': {'desc': None, 'value': 'no'}, 'resume_from_checkpoint': {'desc': None, 'value': None}, 'chunk_size_feed_forward': {'desc': None, 'value': 0}, 'eval_accumulation_steps': {'desc': None, 'value': None}, 'max_position_embeddings': {'desc': None, 'value': 2048}, 'per_gpu_eval_batch_size': {'desc': None, 'value': None}, 'return_dict_in_generate': {'desc': None, 'value': False}, 'torch_empty_cache_steps': {'desc': None, 'value': None}, 'per_gpu_train_batch_size': {'desc': None, 'value': None}, 'push_to_hub_organization': {'desc': None, 'value': None}, 'ds3_gather_for_generation': {'desc': None, 'value': True}, 'include_tokens_per_second': {'desc': None, 'value': False}, 'dataloader_prefetch_factor': {'desc': None, 'value': None}, 'ddp_find_unused_parameters': {'desc': None, 'value': None}, 'include_inputs_for_metrics': {'desc': None, 'value': False}, 'per_device_eval_batch_size': {'desc': None, 'value': 8}, 'use_legacy_prediction_loop': {'desc': None, 'value': False}, 'cross_attention_hidden_size': {'desc': None, 'value': None}, 'gradient_accumulation_steps': {'desc': None, 'value': 4}, 'per_device_train_batch_size': {'desc': None, 'value': 16}, 'vllm_gpu_memory_utilization': {'desc': None, 'value': 0.9}, '_attn_implementation_autoset': {'desc': None, 'value': True}, 'encoder_no_repeat_ngram_size': {'desc': None, 'value': 0}, 'average_tokens_across_devices': {'desc': None, 'value': False}, 'dataloader_persistent_workers': {'desc': None, 'value': False}, 'gradient_checkpointing_kwargs': {'desc': None, 'value': None}, 'include_num_input_tokens_seen': {'desc': None, 'value': False}, 'exponential_decay_length_penalty': {'desc': None, 'value': None}, 'fsdp_transformer_layer_cls_to_wrap': {'desc': None, 'value': None}, 'restore_callback_states_from_checkpoint': {'desc': None, 'value': False}},tags=[])
2025-03-21 18:06:00,767 INFO    SenderThread:704 [dir_watcher.py:__init__():211] watching files in: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_180559-seed-llama-8b-GRPO-resq/files
2025-03-21 18:06:00,767 INFO    SenderThread:704 [sender.py:_start_run_threads():1136] run started: seed-llama-8b-GRPO-resq with start time 1742580298.811836
2025-03-21 18:06:00,775 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: check_version
2025-03-21 18:06:00,775 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: check_version
2025-03-21 18:06:00,851 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: run_start
2025-03-21 18:06:00,868 DEBUG   HandlerThread:704 [system_info.py:__init__():27] System info init
2025-03-21 18:06:00,868 DEBUG   HandlerThread:704 [system_info.py:__init__():42] System info init done
2025-03-21 18:06:00,868 INFO    HandlerThread:704 [system_monitor.py:start():194] Starting system monitor
2025-03-21 18:06:00,868 INFO    SystemMonitor:704 [system_monitor.py:_start():158] Starting system asset monitoring threads
2025-03-21 18:06:00,869 INFO    SystemMonitor:704 [interfaces.py:start():190] Started cpu monitoring
2025-03-21 18:06:00,870 INFO    SystemMonitor:704 [interfaces.py:start():190] Started disk monitoring
2025-03-21 18:06:00,870 INFO    SystemMonitor:704 [interfaces.py:start():190] Started gpu monitoring
2025-03-21 18:06:00,871 INFO    SystemMonitor:704 [interfaces.py:start():190] Started memory monitoring
2025-03-21 18:06:00,871 INFO    SystemMonitor:704 [interfaces.py:start():190] Started network monitoring
2025-03-21 18:06:00,879 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: python_packages
2025-03-21 18:06:00,879 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: python_packages
2025-03-21 18:06:00,924 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: stop_status
2025-03-21 18:06:00,924 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: internal_messages
2025-03-21 18:06:00,924 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: stop_status
2025-03-21 18:06:01,188 DEBUG   SenderThread:704 [sender.py:send():382] send: telemetry
2025-03-21 18:06:01,188 DEBUG   SenderThread:704 [sender.py:send():382] send: config
2025-03-21 18:06:01,189 DEBUG   SenderThread:704 [sender.py:send():382] send: metric
2025-03-21 18:06:01,189 DEBUG   SenderThread:704 [sender.py:send():382] send: telemetry
2025-03-21 18:06:01,189 DEBUG   SenderThread:704 [sender.py:send():382] send: metric
2025-03-21 18:06:01,189 WARNING SenderThread:704 [sender.py:send_metric():1354] Seen metric with glob (shouldn't happen)
2025-03-21 18:06:01,189 DEBUG   SenderThread:704 [sender.py:send():382] send: telemetry
2025-03-21 18:06:01,189 DEBUG   SenderThread:704 [sender.py:send():382] send: telemetry
2025-03-21 18:06:01,189 DEBUG   SenderThread:704 [sender.py:send():382] send: config
2025-03-21 18:06:01,769 INFO    Thread-12 :704 [dir_watcher.py:_on_file_created():271] file/dir created: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_180559-seed-llama-8b-GRPO-resq/files/output.log
2025-03-21 18:06:01,769 INFO    Thread-12 :704 [dir_watcher.py:_on_file_created():271] file/dir created: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_180559-seed-llama-8b-GRPO-resq/files/requirements.txt
2025-03-21 18:06:03,770 INFO    Thread-12 :704 [dir_watcher.py:_on_file_modified():288] file/dir modified: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_180559-seed-llama-8b-GRPO-resq/files/output.log
2025-03-21 18:06:05,191 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:06:10,192 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:06:15,193 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:06:15,880 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: stop_status
2025-03-21 18:06:15,881 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: stop_status
2025-03-21 18:06:15,923 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: internal_messages
2025-03-21 18:06:21,062 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:06:26,063 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:06:30,880 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: stop_status
2025-03-21 18:06:30,880 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: stop_status
2025-03-21 18:06:30,923 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: internal_messages
2025-03-21 18:06:31,140 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:06:31,788 INFO    Thread-12 :704 [dir_watcher.py:_on_file_modified():288] file/dir modified: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_180559-seed-llama-8b-GRPO-resq/files/config.yaml
2025-03-21 18:06:36,353 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:06:41,354 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:06:45,880 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: stop_status
2025-03-21 18:06:45,880 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: stop_status
2025-03-21 18:06:45,923 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: internal_messages
2025-03-21 18:06:47,155 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:06:52,155 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:06:57,156 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:07:00,872 DEBUG   SystemMonitor:704 [system_monitor.py:_start():172] Starting system metrics aggregation loop
2025-03-21 18:07:00,873 DEBUG   SenderThread:704 [sender.py:send():382] send: stats
2025-03-21 18:07:00,880 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: stop_status
2025-03-21 18:07:00,880 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: stop_status
2025-03-21 18:07:00,923 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: internal_messages
2025-03-21 18:07:03,106 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:07:08,107 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:07:10,419 DEBUG   SenderThread:704 [sender.py:send():382] send: exit
2025-03-21 18:07:10,419 INFO    SenderThread:704 [sender.py:send_exit():589] handling exit code: 1
2025-03-21 18:07:10,419 INFO    SenderThread:704 [sender.py:send_exit():591] handling runtime: 69
2025-03-21 18:07:10,421 INFO    SenderThread:704 [sender.py:_save_file():1403] saving file wandb-summary.json with policy end
2025-03-21 18:07:10,421 INFO    SenderThread:704 [sender.py:send_exit():597] send defer
2025-03-21 18:07:10,422 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:07:10,422 INFO    HandlerThread:704 [handler.py:handle_request_defer():172] handle defer: 0
2025-03-21 18:07:10,422 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: defer
2025-03-21 18:07:10,422 INFO    SenderThread:704 [sender.py:send_request_defer():613] handle sender defer: 0
2025-03-21 18:07:10,422 INFO    SenderThread:704 [sender.py:transition_state():617] send defer: 1
2025-03-21 18:07:10,422 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:07:10,422 INFO    HandlerThread:704 [handler.py:handle_request_defer():172] handle defer: 1
2025-03-21 18:07:10,422 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: defer
2025-03-21 18:07:10,422 INFO    SenderThread:704 [sender.py:send_request_defer():613] handle sender defer: 1
2025-03-21 18:07:10,422 INFO    SenderThread:704 [sender.py:transition_state():617] send defer: 2
2025-03-21 18:07:10,422 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:07:10,422 INFO    HandlerThread:704 [handler.py:handle_request_defer():172] handle defer: 2
2025-03-21 18:07:10,422 INFO    HandlerThread:704 [system_monitor.py:finish():203] Stopping system monitor
2025-03-21 18:07:10,423 DEBUG   SystemMonitor:704 [system_monitor.py:_start():179] Finished system metrics aggregation loop
2025-03-21 18:07:10,423 INFO    HandlerThread:704 [interfaces.py:finish():202] Joined cpu monitor
2025-03-21 18:07:10,423 DEBUG   SystemMonitor:704 [system_monitor.py:_start():183] Publishing last batch of metrics
2025-03-21 18:07:10,424 INFO    HandlerThread:704 [interfaces.py:finish():202] Joined disk monitor
2025-03-21 18:07:10,505 INFO    HandlerThread:704 [interfaces.py:finish():202] Joined gpu monitor
2025-03-21 18:07:10,505 INFO    HandlerThread:704 [interfaces.py:finish():202] Joined memory monitor
2025-03-21 18:07:10,505 INFO    HandlerThread:704 [interfaces.py:finish():202] Joined network monitor
2025-03-21 18:07:10,505 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: defer
2025-03-21 18:07:10,505 INFO    SenderThread:704 [sender.py:send_request_defer():613] handle sender defer: 2
2025-03-21 18:07:10,505 INFO    SenderThread:704 [sender.py:transition_state():617] send defer: 3
2025-03-21 18:07:10,505 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:07:10,505 INFO    HandlerThread:704 [handler.py:handle_request_defer():172] handle defer: 3
2025-03-21 18:07:10,506 DEBUG   SenderThread:704 [sender.py:send():382] send: stats
2025-03-21 18:07:10,507 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: defer
2025-03-21 18:07:10,507 INFO    SenderThread:704 [sender.py:send_request_defer():613] handle sender defer: 3
2025-03-21 18:07:10,507 INFO    SenderThread:704 [sender.py:transition_state():617] send defer: 4
2025-03-21 18:07:10,507 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:07:10,507 INFO    HandlerThread:704 [handler.py:handle_request_defer():172] handle defer: 4
2025-03-21 18:07:10,507 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: defer
2025-03-21 18:07:10,507 INFO    SenderThread:704 [sender.py:send_request_defer():613] handle sender defer: 4
2025-03-21 18:07:10,507 INFO    SenderThread:704 [sender.py:transition_state():617] send defer: 5
2025-03-21 18:07:10,508 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:07:10,508 INFO    HandlerThread:704 [handler.py:handle_request_defer():172] handle defer: 5
2025-03-21 18:07:10,508 DEBUG   SenderThread:704 [sender.py:send():382] send: summary
2025-03-21 18:07:10,510 INFO    SenderThread:704 [sender.py:_save_file():1403] saving file wandb-summary.json with policy end
2025-03-21 18:07:10,510 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: defer
2025-03-21 18:07:10,510 INFO    SenderThread:704 [sender.py:send_request_defer():613] handle sender defer: 5
2025-03-21 18:07:10,510 INFO    SenderThread:704 [sender.py:transition_state():617] send defer: 6
2025-03-21 18:07:10,510 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:07:10,510 INFO    HandlerThread:704 [handler.py:handle_request_defer():172] handle defer: 6
2025-03-21 18:07:10,510 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: defer
2025-03-21 18:07:10,510 INFO    SenderThread:704 [sender.py:send_request_defer():613] handle sender defer: 6
2025-03-21 18:07:10,510 INFO    SenderThread:704 [sender.py:transition_state():617] send defer: 7
2025-03-21 18:07:10,510 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: status_report
2025-03-21 18:07:10,510 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:07:10,510 INFO    HandlerThread:704 [handler.py:handle_request_defer():172] handle defer: 7
2025-03-21 18:07:10,510 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: defer
2025-03-21 18:07:10,510 INFO    SenderThread:704 [sender.py:send_request_defer():613] handle sender defer: 7
2025-03-21 18:07:10,812 INFO    Thread-12 :704 [dir_watcher.py:_on_file_created():271] file/dir created: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_180559-seed-llama-8b-GRPO-resq/files/wandb-summary.json
2025-03-21 18:07:11,282 INFO    SenderThread:704 [sender.py:transition_state():617] send defer: 8
2025-03-21 18:07:11,282 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:07:11,282 INFO    HandlerThread:704 [handler.py:handle_request_defer():172] handle defer: 8
2025-03-21 18:07:11,282 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: defer
2025-03-21 18:07:11,282 INFO    SenderThread:704 [sender.py:send_request_defer():613] handle sender defer: 8
2025-03-21 18:07:11,282 INFO    SenderThread:704 [job_builder.py:build():296] Attempting to build job artifact
2025-03-21 18:07:11,283 INFO    SenderThread:704 [sender.py:transition_state():617] send defer: 9
2025-03-21 18:07:11,283 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:07:11,283 INFO    HandlerThread:704 [handler.py:handle_request_defer():172] handle defer: 9
2025-03-21 18:07:11,283 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: defer
2025-03-21 18:07:11,283 INFO    SenderThread:704 [sender.py:send_request_defer():613] handle sender defer: 9
2025-03-21 18:07:11,283 INFO    SenderThread:704 [dir_watcher.py:finish():358] shutting down directory watcher
2025-03-21 18:07:11,419 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: poll_exit
2025-03-21 18:07:11,813 INFO    SenderThread:704 [dir_watcher.py:_on_file_modified():288] file/dir modified: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_180559-seed-llama-8b-GRPO-resq/files/output.log
2025-03-21 18:07:11,814 INFO    SenderThread:704 [dir_watcher.py:finish():388] scan: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_180559-seed-llama-8b-GRPO-resq/files
2025-03-21 18:07:11,814 INFO    SenderThread:704 [dir_watcher.py:finish():402] scan save: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_180559-seed-llama-8b-GRPO-resq/files/config.yaml config.yaml
2025-03-21 18:07:11,814 INFO    SenderThread:704 [dir_watcher.py:finish():402] scan save: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_180559-seed-llama-8b-GRPO-resq/files/requirements.txt requirements.txt
2025-03-21 18:07:11,814 INFO    SenderThread:704 [dir_watcher.py:finish():402] scan save: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_180559-seed-llama-8b-GRPO-resq/files/output.log output.log
2025-03-21 18:07:11,817 INFO    SenderThread:704 [dir_watcher.py:finish():402] scan save: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_180559-seed-llama-8b-GRPO-resq/files/wandb-summary.json wandb-summary.json
2025-03-21 18:07:11,819 INFO    SenderThread:704 [sender.py:transition_state():617] send defer: 10
2025-03-21 18:07:11,819 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: poll_exit
2025-03-21 18:07:11,819 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:07:11,819 INFO    HandlerThread:704 [handler.py:handle_request_defer():172] handle defer: 10
2025-03-21 18:07:11,821 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: defer
2025-03-21 18:07:11,821 INFO    SenderThread:704 [sender.py:send_request_defer():613] handle sender defer: 10
2025-03-21 18:07:11,821 INFO    SenderThread:704 [file_pusher.py:finish():175] shutting down file pusher
2025-03-21 18:07:12,404 INFO    wandb-upload_2:704 [upload_job.py:push():131] Uploaded file /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_180559-seed-llama-8b-GRPO-resq/files/output.log
2025-03-21 18:07:12,404 INFO    wandb-upload_1:704 [upload_job.py:push():131] Uploaded file /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_180559-seed-llama-8b-GRPO-resq/files/requirements.txt
2025-03-21 18:07:12,406 INFO    wandb-upload_0:704 [upload_job.py:push():131] Uploaded file /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_180559-seed-llama-8b-GRPO-resq/files/config.yaml
2025-03-21 18:07:12,410 INFO    wandb-upload_3:704 [upload_job.py:push():131] Uploaded file /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_180559-seed-llama-8b-GRPO-resq/files/wandb-summary.json
2025-03-21 18:07:12,419 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: poll_exit
2025-03-21 18:07:12,420 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: poll_exit
2025-03-21 18:07:12,610 INFO    Thread-11 (_thread_body):704 [sender.py:transition_state():617] send defer: 11
2025-03-21 18:07:12,610 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:07:12,610 INFO    HandlerThread:704 [handler.py:handle_request_defer():172] handle defer: 11
2025-03-21 18:07:12,611 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: defer
2025-03-21 18:07:12,611 INFO    SenderThread:704 [sender.py:send_request_defer():613] handle sender defer: 11
2025-03-21 18:07:12,611 INFO    SenderThread:704 [file_pusher.py:join():181] waiting for file pusher
2025-03-21 18:07:12,611 INFO    SenderThread:704 [sender.py:transition_state():617] send defer: 12
2025-03-21 18:07:12,611 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:07:12,611 INFO    HandlerThread:704 [handler.py:handle_request_defer():172] handle defer: 12
2025-03-21 18:07:12,611 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: defer
2025-03-21 18:07:12,611 INFO    SenderThread:704 [sender.py:send_request_defer():613] handle sender defer: 12
2025-03-21 18:07:12,611 INFO    SenderThread:704 [file_stream.py:finish():595] file stream finish called
2025-03-21 18:07:12,779 INFO    SenderThread:704 [file_stream.py:finish():599] file stream finish is done
2025-03-21 18:07:12,779 INFO    SenderThread:704 [sender.py:transition_state():617] send defer: 13
2025-03-21 18:07:12,780 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:07:12,780 INFO    HandlerThread:704 [handler.py:handle_request_defer():172] handle defer: 13
2025-03-21 18:07:12,780 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: defer
2025-03-21 18:07:12,780 INFO    SenderThread:704 [sender.py:send_request_defer():613] handle sender defer: 13
2025-03-21 18:07:12,780 INFO    SenderThread:704 [sender.py:transition_state():617] send defer: 14
2025-03-21 18:07:12,780 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: defer
2025-03-21 18:07:12,780 INFO    HandlerThread:704 [handler.py:handle_request_defer():172] handle defer: 14
2025-03-21 18:07:12,780 DEBUG   SenderThread:704 [sender.py:send():382] send: final
2025-03-21 18:07:12,781 DEBUG   SenderThread:704 [sender.py:send():382] send: footer
2025-03-21 18:07:12,781 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: defer
2025-03-21 18:07:12,781 INFO    SenderThread:704 [sender.py:send_request_defer():613] handle sender defer: 14
2025-03-21 18:07:12,781 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: poll_exit
2025-03-21 18:07:12,781 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: poll_exit
2025-03-21 18:07:12,781 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: poll_exit
2025-03-21 18:07:12,782 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: poll_exit
2025-03-21 18:07:12,782 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: server_info
2025-03-21 18:07:12,782 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: server_info
2025-03-21 18:07:12,783 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: get_summary
2025-03-21 18:07:12,784 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: sampled_history
2025-03-21 18:07:12,784 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: internal_messages
2025-03-21 18:07:12,784 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: job_info
2025-03-21 18:07:12,927 DEBUG   SenderThread:704 [sender.py:send_request():409] send_request: job_info
2025-03-21 18:07:12,928 INFO    MainThread:704 [wandb_run.py:_footer_history_summary_info():3857] rendering history
2025-03-21 18:07:12,928 INFO    MainThread:704 [wandb_run.py:_footer_history_summary_info():3889] rendering summary
2025-03-21 18:07:12,928 INFO    MainThread:704 [wandb_run.py:_footer_sync_info():3816] logging synced files
2025-03-21 18:07:12,928 DEBUG   HandlerThread:704 [handler.py:handle_request():146] handle_request: shutdown
2025-03-21 18:07:12,928 INFO    HandlerThread:704 [handler.py:finish():869] shutting down handler
2025-03-21 18:07:13,784 INFO    WriterThread:704 [datastore.py:close():296] close: /lid/home/saydalie/multimodal_cot/SEED/wandb/run-20250321_180559-seed-llama-8b-GRPO-resq/run-seed-llama-8b-GRPO-resq.wandb
2025-03-21 18:07:13,927 INFO    SenderThread:704 [sender.py:finish():1572] shutting down sender
2025-03-21 18:07:13,928 INFO    SenderThread:704 [file_pusher.py:finish():175] shutting down file pusher
2025-03-21 18:07:13,928 INFO    SenderThread:704 [file_pusher.py:join():181] waiting for file pusher
